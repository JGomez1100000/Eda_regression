{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#StandardScaler es una herramienta de preprocesamiento de datos utilizada para escalar y \n",
    "# normalizar los datos numéricos para que estén todos dentro de la misma escala. \n",
    "# Esto es útil cuando se trabaja con algoritmos de aprendizaje automático, ya que los algoritmos pueden tener problemas para converger \n",
    "# correctamente si los datos están muy dispersos. El escalado de los datos también ayuda a evitar la sobreestimación de ciertos atributos.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#MinMaxScaler es una herramienta de escalado de características usada para ajustar los datos a un rango específico.\n",
    "#Esta herramienta es útil cuando se manejan datos con un gran rango de valores, como en el caso de datos que contienen valores entre cero y un millón.\n",
    "#Esta herramienta permite normalizar los datos a un rango específico, como 0 a 1.\n",
    "#Permite que los algoritmos de aprendizaje automático trabajen con los datos de manera más eficiente,\n",
    "#ya que los algoritmos suelen funcionar mejor con datos normalizados.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "#Normalizer en Python se utiliza para normalizar (estandarizar) los datos de entrada para que sean adecuados para la computación.\n",
    "#Esto se hace para garantizar que los datos sean estandarizados y sean homogéneos en su formato para que sean más fáciles de usar. \n",
    "#Normalizar los datos es esencial para los algoritmos de Machine Learning, ya que le ayuda a eliminar los efectos de la escala y el sesgo para mejorar\n",
    "#la precisión de los modelos.\n",
    "scaler = Normalizer()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.preprocessing import Binarizer\n",
    "#Binarizer se usa para transformar cualquier valor numérico a uno binario, esto es, 0 o 1.\n",
    "# Esto es útil para tareas de clasificación binaria. Esto es especialmente útil para los algoritmos de aprendizaje de máquinas,\n",
    "#  donde se necesita una salida binaria para la clasificación. Por ejemplo, se puede usar Binarizer para convertir un conjunto de características\n",
    "#  numéricas en una matriz binaria, donde cada celda es una característica binaria. Esto proporciona una mejor representación para los algoritmos \n",
    "# de aprendizaje de máquinas, ya que los algoritmos de aprendizaje de máquinas se basan en la manipulación de vectores binarios.\n",
    "scaler = Binarizer(threshold=0.0).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#PolynomialFeatures en python se usa para generar características nuevas a partir de características existentes en los datos.\n",
    "#Esto se usa comúnmente para construir modelos predictivos, como regresión lineal, regresión logística y árboles de decisión.\n",
    "#Esta herramienta genera nuevas características a partir de la combinación lineal de los atributos de los datos,\n",
    "#lo que nos da una mejor representación para el modelo.\n",
    "#Esto aumenta la flexibilidad del modelo y da mejores resultados.\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "#FunctionTransformer es una herramienta de preprocesamiento de datos de Scikit-learn que permite a los usuarios aplicar una función personalizada \n",
    "#a un conjunto de datos de entrada. Esta herramienta se puede utilizar para realizar transformaciones de datos tales como la normalización, \n",
    "#la estandarización, la codificación, la binarización, entre otras. \n",
    "#Esta herramienta es útil para aplicar operaciones directamente a los datos sin tener que codificar toda la lógica en una función.\n",
    "transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#El LabelEncoder de Python es una herramienta de preprocesamiento de datos que se utiliza para convertir variables categóricas en numéricas, \n",
    "#es decir, se etiquetan los diferentes valores de las variables. Esto es útil para alimentar modelos de aprendizaje automático,\n",
    "#ya que la mayoría de los modelos funcionan mejor con datos numéricos. \n",
    "#LabelEncoder se usa para convertir etiquetas de texto o números enteros a una representación numérica.\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#LabelBinarizer en python sirve para convertir etiquetas categóricas a etiquetas binarias.\n",
    "#Esto significa que convierte etiquetas de texto o números en vectores binarios,\n",
    "#donde cada etiqueta se convierte en un vector de una dimensión con una longitud igual al número de clases. \n",
    "#Esto se usa a menudo en la clasificación de problemas donde los datos de entrenamiento están etiquetados con valores discretos \n",
    "#para indicar la clase a la que pertenecen. El uso de LabelBinarizer en python puede reducir el tiempo de ejecución de los modelos de clasificación,\n",
    "#ya que reduce el número de características necesarias para entrenar el modelo.\n",
    "encoder = LabelBinarizer()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "#MultiLabelBinarizer es una herramienta de Python que se utiliza para convertir etiquetas de cadena a etiquetas binarias de Python.\n",
    "#Esta herramienta es útil cuando se trabaja con etiquetas múltiples. Por ejemplo, si una imagen se etiqueta como \"perro\" y \"gato\", \n",
    "# se puede usar MultiLabelBinarizer para convertir estas etiquetas en dos etiquetas binarias, \"perro\" y \"gato\". \n",
    "#Esto permite a los algoritmos de aprendizaje automático entender mejor la estructura de los datos etiquetados.\n",
    "encoder = MultiLabelBinarizer()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#El OrdinalEncoder en Python se usa para codificar variables cualitativas ordinales en valores numéricos. \n",
    "#Esta codificación es útil para poder usar algoritmos de aprendizaje automático que solo trabajan con datos numéricos. \n",
    "#`Los datos cualitativos ordinales son aquellos en los que los valores varían entre diferentes categorías, pero hay un orden entre ellas. \n",
    "#Por ejemplo, si estamos codificando la variable \"calificación\", los valores posibles pueden ser \"malo\", \"regular\", \"bueno\" y \"excelente\". \n",
    "#El OrdinalEncoder cambiará cada uno de estos valores por un número entero,\n",
    "#por ejemplo \"malo\" se convertiría en 0, \"regular\" en 1, \"bueno\" en 2 y \"excelente\" en 3.\n",
    "encoder = OrdinalEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "#KBinsDiscretizer es una función en Python que se utiliza para convertir variables continuas en variables discretas.\n",
    "#Esto es útil para analizar datos que no pueden ser representados en una escala continua, como el ingreso anual, el puntaje de un examen, \n",
    "#la edad, etc. La función KBinsDiscretizer se puede utilizar para crear un conjunto de clases discretas, lo que permite agrupar \n",
    "#los datos en categorías y realizar un análisis estadístico más preciso. \n",
    "#Esta función es también útil para reducir el ruido en los datos al agrupar los datos en los límites de cada clase.\n",
    "encoder = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "#El módulo PowerTransformer de Python es una herramienta útil para transformar datos de entrada para un mejor ajuste a modelos estadísticos. \n",
    "#Esta herramienta se puede utilizar para transformar variables numéricas a distribuciones más adecuadas para modelos estadísticos, como la distribución\n",
    "#Normal o la distribución logarítmica. Esto mejora el rendimiento de los modelos de aprendizaje automático, \n",
    "#ya que reducen la sensibilidad a los valores atípicos.\n",
    "#Esto también puede mejorar la precisión de los modelos de clasificación.\n",
    "transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "#El QuantileTransformer de Python se utiliza para ajustar los datos de entrada de forma que los valores de salida estén distribuidos de manera uniforme.\n",
    "#Esta técnica es útil para preprocesar los datos antes de entrenar un modelo de aprendizaje automático, ya que ayuda a reducir la posible varianza\n",
    "#entre los datos de entrenamiento y los datos de prueba. Esto mejora la capacidad de generalización de un modelo de aprendizaje automático. \n",
    "#El QuantileTransformer también se puede utilizar para normalizar los datos antes de la aplicación de algunos algoritmos de aprendizaje automático,\n",
    "#como KNN o SVM.\n",
    "transformer = QuantileTransformer(n_quantiles=10, output_distribution='normal', random_state=0)\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#RobustScaler es una herramienta de escalado de características de Python diseñada para ser robusta ante los valores extremos.\n",
    "#Esto significa que RobustScaler tratará los valores atípicos como valores de media y los no atípicos como valores extremos.\n",
    "#Esto es útil cuando se trabaja con datos que contienen muchos valores atípicos. \n",
    "#Las herramientas de escalado tradicionales, como MinMaxScaler, no manejan bien los valores atípicos y pueden resultar en una distribución deformada\n",
    "#de los datos. RobustScaler, por otro lado, minimiza la distorsión de los datos.\n",
    "scaler = RobustScaler(quantile_range=(25.0, 75.0), with_centering=True, with_scaling=True)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "#MaxAbsScaler es una herramienta de escalado de datos en Python que se utiliza para transformar los datos de manera que los valores más grandes sean\n",
    "#el valor máximo absoluto de cada feature. Esta herramienta es útil cuando se trabaja con conjuntos de datos que contienen valores que varían mucho \n",
    "#entre sí, ya que le da a cada valor un rango de 0 a 1. Esto ayuda a normalizar los datos y a reducir los efectos de la desigualdad en los datos.\n",
    "#Además, MaxAbsScaler también se usa para mejorar la precisión y la exactitud de los modelos de aprendizaje automático."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
